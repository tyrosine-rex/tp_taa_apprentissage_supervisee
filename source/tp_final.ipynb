{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP TAA\n",
    "\n",
    "\n",
    "lien git : https://github.com/tyrosine-rex/tp_taa_apprentissage_supervisee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "import lib.taa_tools as taa\n",
    "\n",
    "np.set_printoptions(threshold=10000,suppress=True) \n",
    "filterwarnings('ignore')\n",
    "\n",
    "CREDIT_SCORE = \"../data/credit_scoring.csv\"\n",
    "CREDIT_SCORE_HET = \"../data/credit.data\"\n",
    "SPAM = \"../data/SMSSpamCollection.data\"\n",
    "YELP = \"../data/yelp-text-by-stars.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Apprentissage supervisé : **Feature engineering et Classification**\n",
    "\n",
    "## 1) Chargement des données et préparation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit = pd.read_csv(CREDIT_SCORE, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taa.explore_data(df_credit, \"df_credit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de donnée 'credit_scoring.csv' présente 14 colonnes/variables et 4375 lignes/enregistrements. Chaque enregistrement est une demande de crédit, pour chaque demandeur est renseigné 13 variables d'entrée et 1 variable de sortie. Toutes les variables sont de natures numériques (certaines sont binaires). \n",
    "La colonne 'Status' est la variable de sortie que l'on va essayer de prédire à partir des variables d'entrée. Son codage correspond à:\n",
    "- 1: Solvable (72.21%)\n",
    "- 0: Non-solvable (27.79%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_prior = taa.calc_prior_accuracy(df_credit[\"Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = df_credit.values[:, :-1], df_credit.values[:, -1]\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Apprentissage et évaluation de modèles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "COLS_EVAL = [\"method\", \"preprocess\", \"precision\", \"accuracy\", \"recall\", \"VP\", \"VN\", \"FP\", \"FN\", \"args\"]\n",
    "DATAS=(xtrain, ytrain, xtest, ytest)\n",
    "\n",
    "# tests\n",
    "cart_test = taa.test_model(*DATAS, DecisionTreeClassifier, random_state=1)\n",
    "knn_test = taa.test_model(*DATAS, KNeighborsClassifier, n_neighbors=5)\n",
    "mlp_test = taa.test_model(*DATAS, MLPClassifier, hidden_layer_sizes=(40, 20), random_state=1)\n",
    "\n",
    "df_comparative = pd.concat([cart_test, knn_test, mlp_test], ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit la **precision** (ou **positive predictive value**): $\\frac{VP}{VP+FP}$ \"Parmis les prédictions positives, lesquelles sont justes/vraies\"\n",
    "\n",
    "On définit l'**accuracy** : $\\frac{VP+VN}{VP+FP+VN+FN}$ \"Parmis l'ensemble des prédictions, lesquelles sont justes\"\n",
    "\n",
    "On définit le **recall** (ou **sensibilité** ou **true positive rate**): $\\frac{VP}{VP+FN}$ \"Parmis les cas postifs, lesquelles sont prédites\"\n",
    "\n",
    "Dans notre situation, nous représentons l'assureur, nous voulons éviter les impayés ! il faut alors minimiser au possible les **faux positifs** (c'est à dire ne pas attribuer un prêt alors qu'un agent ne l'aurait pas fait). \n",
    "Ainsi le critère de **précision** est plus important que le recall puisque son calcul prend en compte les faux positifs (la précision augment à mesure que les FP diminue).\n",
    "\n",
    "Dans ce premier test, c'est la méthode par arbre de décision qui a la plus basse precision (0.82 c'est le plus prudent) mais au prix d'une nombre plus faible de call positif (et par conséquent moins de client).\n",
    "Bien que toutes les méthodes ont une accuracy quasi-similaire, leurs décisions sont très différentes à en regarder les matrices de confusion associée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Normalisation des variables continues :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Standard scaling datas\n",
    "stdScale=StandardScaler()\n",
    "stdScale.fit(xtrain)\n",
    "xtrain_ss, xtest_ss = stdScale.transform(xtrain), stdScale.transform(xtest)\n",
    "\n",
    "# Min max scaling datas\n",
    "mmScale= MinMaxScaler()\n",
    "mmScale.fit(xtrain)\n",
    "xtrain_mm, xtest_mm = mmScale.transform(xtrain), mmScale.transform(xtest)\n",
    "\n",
    "DATAS_SS = (xtrain_ss, ytrain, xtest_ss, ytest)\n",
    "DATAS_MM = (xtrain_mm, ytrain, xtest_mm, ytest)\n",
    "\n",
    "# test\n",
    "cart_test_ss = taa.test_model(*DATAS_SS, DecisionTreeClassifier, random_state=1, preprocess=\"StdScale\")\n",
    "cart_test_mm = taa.test_model(*DATAS_MM, DecisionTreeClassifier, random_state=1, preprocess=\"MinMaxScale\")\n",
    "knn_test_ss = taa.test_model(*DATAS_SS, KNeighborsClassifier, n_neighbors=5, preprocess=\"StdScale\")\n",
    "knn_test_mm = taa.test_model(*DATAS_MM, KNeighborsClassifier, n_neighbors=5, preprocess=\"MinMaxScale\")\n",
    "mlp_test_ss = taa.test_model(*DATAS_SS, MLPClassifier, hidden_layer_sizes=(40, 20), random_state=1, preprocess=\"StdScale\")\n",
    "mlp_test_mm = taa.test_model(*DATAS_MM, MLPClassifier, hidden_layer_sizes=(40, 20), random_state=1, preprocess=\"MinMaxScale\")\n",
    "\n",
    "df_comparative = pd.concat([df_comparative, \n",
    "        cart_test_ss, knn_test_ss, mlp_test_ss,\n",
    "        cart_test_mm, knn_test_mm, mlp_test_mm\n",
    "        ], ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on procède à des normalisations de données:\n",
    "- **StandardScaler()**: Centre et réduit les données pour chaque colonne\n",
    "- **MinMaxScaler()**: Normalise les données dans un intervalle de 0 et 1 pour chaque colonne\n",
    "\n",
    "De manière globale, la StandardScale est plus interressante car elle augmente plus la precision que la MinMaxScale\n",
    "\n",
    "Nous discuterons de ces préproccessing à la fin de la partie \"*I)5) Sélection de variables*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Création de nouvelles variables caractéristiques par combinaisons linéaires des variables initiales :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA computation\n",
    "pca = PCA()\n",
    "pca.fit(xtrain_ss)\n",
    "pca_train, pca_test = pca.transform(xtrain_ss), pca.transform(xtest_ss)\n",
    "\n",
    "# bind the 3 first PCA axis to std scalled x datas\n",
    "xtrain_ss_pca = np.column_stack((xtrain_ss, pca_train[:, :3]))\n",
    "xtest_ss_pca = np.column_stack((xtest_ss, pca_test[:, :3]))\n",
    "\n",
    "DATAS_SS_PCA = (xtrain_ss_pca, ytrain, xtest_ss_pca, ytest)\n",
    "\n",
    "# test\n",
    "cart_test_ss_pca = taa.test_model(*DATAS_SS_PCA, DecisionTreeClassifier, random_state=1, preprocess=\"StdScale + PCA\")\n",
    "knn_test_ss_pca = taa.test_model(*DATAS_SS_PCA, KNeighborsClassifier, n_neighbors=5, preprocess=\"StdScale + PCA\")\n",
    "mlp_test_ss_pca = taa.test_model(*DATAS_SS_PCA, MLPClassifier, hidden_layer_sizes=(40, 20), random_state=1, preprocess=\"StdScale + PCA\")\n",
    "\n",
    "df_comparative = pd.concat([df_comparative, cart_test_ss_pca, knn_test_ss_pca, mlp_test_ss_pca], ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **PCA().fit()** nous permet:\n",
    "- Identifier les facteurs d'inerties (combinaison linéaire de toutes les variables) avec nos données. Ces facteurs constituent la base d'un espace où la dispersion des données est maximale.\n",
    "- Classer ces facteurs d'inerties par leurs participations à la variance des données.\n",
    "\n",
    "La **PCA().transform()** nous permet:\n",
    "- Trouve les coordonnées de nos données dans un nouvel espace (dont la base sont les facteurs d'inerties trouvés). On ne garde que celles des 3 premiers facteurs d'inertie)\n",
    "\n",
    "Ainsi on devrait **augmenter le signal/bruit** (car on prends les facteurs les plus explicatifs) ce qui devrait aider nos prédictions.\n",
    "\n",
    "Nous discuterons de ces préproccessing à la fin de la partie \"*I)5) Sélection de variables*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Sélection de variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state = 1)\n",
    "clf.fit(xtrain_ss, ytrain)\n",
    "importances=clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],axis=0)\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "features = df_credit.columns.values\n",
    "print(features[sorted_idx])\n",
    "padding = np.arange(xtrain_ss.size/len(xtrain_ss)) + 0.5 \n",
    "plt.barh(padding, importances[sorted_idx],xerr=std[sorted_idx], align='center') \n",
    "plt.yticks(padding, features[sorted_idx]) \n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.title(\"Variable Importance\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"CART\": DecisionTreeClassifier(random_state=1),\n",
    "    \"MLP\" : MLPClassifier(hidden_layer_sizes=(40, 20), random_state=1),\n",
    "    \"KNN\" : KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "trim_test = taa.test_trimming(*DATAS_SS, MODELS, sorted_idx)\n",
    "\n",
    "taa.results_test_trimming(trim_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans chacun des cas (ou presque) on atteint soit un pic (MLP) soit un plateau (KNN et CART) d'accuracy à partir de 7 variables incluses (rank par leurs importances).\n",
    "Après ce seuil, il y a une baisse d'accuracy -> effet du bruit sur les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimming\n",
    "SIGNIFICANCE_COLS = sorted_idx[:8]\n",
    "X_trimmed = X[:, SIGNIFICANCE_COLS]\n",
    "\n",
    "xtrain_trim, xtest_trim, ytrain, ytest = train_test_split(X_trimmed, Y, test_size=0.5, random_state=1)\n",
    "\n",
    "# Stdscale\n",
    "stdScale=StandardScaler()\n",
    "stdScale.fit(xtrain_trim)\n",
    "\n",
    "#Trim + stdScale\n",
    "xtrain_trim_ss = stdScale.transform(xtrain_trim)\n",
    "xtest_trim_ss = stdScale.transform(xtest_trim)\n",
    "\n",
    "#Trim + stdScale + PCA\n",
    "xtrain_trim_ss_pca = np.column_stack((xtrain_trim_ss, pca_train[:, :3]))\n",
    "xtest_trim_ss_pca = np.column_stack((xtest_trim_ss, pca_test[:, :3]))\n",
    "\n",
    "\n",
    "DATAS_TRIM_SS_PCA = (xtrain_trim_ss_pca, ytrain, xtest_trim_ss_pca, ytest)\n",
    "DATAS_TRIM_SS = (xtrain_trim_ss, ytrain, xtest_trim_ss, ytest)\n",
    "\n",
    "# test Trim + stdScale\n",
    "cart_test_trim_ss = taa.test_model(*DATAS_TRIM_SS, DecisionTreeClassifier, random_state=1, preprocess=\"Trim + StdScale\")\n",
    "knn_test_trim_ss = taa.test_model(*DATAS_TRIM_SS, KNeighborsClassifier, n_neighbors=5, preprocess=\"Trim + StdScale\")\n",
    "mlp_test_trim_ss = taa.test_model(*DATAS_TRIM_SS, MLPClassifier, hidden_layer_sizes=(40, 20), random_state=1, preprocess=\"Trim + StdScale\")\n",
    "\n",
    "# test Trim + stdScale + PCA\n",
    "cart_test_trim_ss_pca = taa.test_model(*DATAS_TRIM_SS_PCA, DecisionTreeClassifier, random_state=1, preprocess=\"Trim + StdScale + PCA\")\n",
    "knn_test_trim_ss_pca = taa.test_model(*DATAS_TRIM_SS_PCA, KNeighborsClassifier, n_neighbors=5, preprocess=\"Trim + StdScale + PCA\")\n",
    "mlp_test_trim_ss_pca = taa.test_model(*DATAS_TRIM_SS_PCA, MLPClassifier, hidden_layer_sizes=(40, 20), random_state=1, preprocess=\"Trim + StdScale + PCA\")\n",
    "\n",
    "\n",
    "df_comparative = pd.concat([df_comparative, \n",
    "        cart_test_trim_ss, knn_test_trim_ss, mlp_test_trim_ss,\n",
    "        cart_test_trim_ss_pca, knn_test_trim_ss_pca, mlp_test_trim_ss_pca\n",
    "        ], ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparatif des preprocessing:\")\n",
    "df_comparative.sort_values(\"precision\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on peut voir que de manière globale, les MLP s'en sorte mieux (en terme de precision) que les autres, à condition d'avoir un préprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taa.comparative_preprocessing(df_comparative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on peut remarquer trouver le meilleur preprocessing pour chaque type de modèle, en fonction de nos besoin (precision):\n",
    "- **TRIMMING + StandardScale** pour MLP et KNN\n",
    "- Et **StandardScale + PCA** pour CART "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparative.pivot_table(\n",
    "    values=['accuracy', 'precision', 'recall'], \n",
    "    index=[\"preprocess\"], \n",
    "    aggfunc=np.mean).sort_values(\"precision\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et enfin, on peut ordonner les meilleures techniques de preprocessing, celle qui marche le mieux en moyenne du point de vue de la precision:\n",
    "\n",
    "1. Trim + StdScale\t\n",
    "2. StdScale + PCA\t\n",
    "3. Trim + StdScale + PCA\t\n",
    "4. StdScale\t\n",
    "5. MinMaxScale\n",
    "6. (aucun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramétrage des classifieurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "@taa.cache_pickle  #to save the result inside ./res/__cache_pickle__\n",
    "def find_best_param(sk_function, params, X_train, Y_train):\n",
    "    gs = GridSearchCV(sk_function(), params, scoring=\"precision\") #we target the best precision score)\n",
    "    gs.fit(X_train, Y_train)\n",
    "    return gs\n",
    "\n",
    "\n",
    "parameters_knn = {\n",
    "    \"n_neighbors\" : [i for i in range(1, 100, 5)],\n",
    "    \"weights\" : [\"uniform\", \"distance\"],\n",
    "    \"algorithm\" : ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "parameters_cart = {\n",
    "    \"criterion\" : [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"splitter\" : [\"best\", \"random\"],\n",
    "    \"max_depth\" : [i for i in range(1, 25)]\n",
    "}\n",
    "\n",
    "parameters_mlp = {\n",
    "    \"activation\" : [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"hidden_layer_sizes\" : [(L1, L2) for L1 in range(15, 121, 15) for L2 in range(int(L1*0.2), int(L1*0.8)+1, int(L1/5))]\n",
    "}\n",
    "\n",
    "#grid search\n",
    "gs_KNN = find_best_param(KNeighborsClassifier, parameters_knn, xtrain_trim_ss, ytrain)\n",
    "gs_CART = find_best_param(DecisionTreeClassifier, parameters_cart, xtrain_ss_pca, ytrain)\n",
    "gs_MLP = find_best_param(MLPClassifier, parameters_mlp, xtrain_trim_ss, ytrain)\n",
    "\n",
    "print(\"KNN\", gs_KNN.best_params_, \"with precision:\", gs_KNN.best_score_)\n",
    "print(\"CART\", gs_CART.best_params_, \"with precision:\", gs_CART.best_score_)\n",
    "print(\"MLP\", gs_MLP.best_params_, \"with precision:\", gs_MLP.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|modèle|preprocessing|params|\n",
    "|---|---|---|\n",
    "|KNN|trim+stdScale|{'algorithm': 'auto', 'n_neighbors': 6, 'weights': 'uniform'}|\n",
    "|MLP|trim+stdScale|{'activation': 'relu', 'hidden_layer_sizes': (105, 42)}|\n",
    "|CART|stdScale+PCA|{'criterion': 'entropy', 'max_depth': 4, 'splitter': 'best'}|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un pipeline :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from pickle import load, dump\n",
    "\n",
    "\n",
    "@taa.cache_pickle  #to save the result into ./res/__cache_pickle__\n",
    "def fit_pipeline(pipeline, X_train, Y_train):\n",
    "    pipeline.fit(X_train, Y_train)\n",
    "    return pipeline\n",
    "\n",
    "# CART preprocess\n",
    "STD_PCA = Pipeline([\n",
    "    (\"stdScale\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=3))\n",
    "])\n",
    "\n",
    "STDwithSTD_PCA=FeatureUnion([\n",
    "    (\"stdScale\", StandardScaler()),\n",
    "    (\"std+pca\", STD_PCA)\n",
    "])\n",
    "\n",
    "# CART\n",
    "CART_PIPE=Pipeline([\n",
    "    (\"preprocess\", STDwithSTD_PCA),\n",
    "    (\"estimator\", DecisionTreeClassifier(**gs_CART.best_params_))\n",
    "])\n",
    "\n",
    "# KNN and MLP preprocess\n",
    "TRIM = ColumnTransformer([\n",
    "    (\"trim\", \"passthrough\", SIGNIFICANCE_COLS)\n",
    "])\n",
    "\n",
    "TRIM_STD=Pipeline([\n",
    "    (\"trim\", TRIM),\n",
    "    (\"stdScale\", StandardScaler())\n",
    "])\n",
    "\n",
    "# MLP\n",
    "MLP_PIPE=Pipeline([\n",
    "    (\"preprocess\", TRIM_STD),\n",
    "    (\"estimator\", MLPClassifier(**gs_MLP.best_params_))\n",
    "])\n",
    "\n",
    "# KNN\n",
    "KNN_PIPE=Pipeline([\n",
    "    (\"preprocess\", TRIM_STD),\n",
    "    (\"estimator\", KNeighborsClassifier(**gs_KNN.best_params_))\n",
    "])\n",
    "\n",
    "# train pipelines with RAW DATA\n",
    "CART_PIPE = fit_pipeline(CART_PIPE, xtrain, ytrain)\n",
    "MLP_PIPE = fit_pipeline(MLP_PIPE, xtrain, ytrain)\n",
    "KNN_PIPE = fit_pipeline(KNN_PIPE, xtrain, ytrain)\n",
    "\n",
    "# save it with pickle\n",
    "dump(CART_PIPE, open(\"../res/pipe_cart.pkl\", \"wb\"))\n",
    "dump(MLP_PIPE, open(\"../res/pipe_mlp.pkl\", \"wb\"))\n",
    "dump(KNN_PIPE, open(\"../res/pipe_knn.pkl\", \"wb\"))\n",
    "\n",
    "del KNN_PIPE, CART_PIPE, MLP_PIPE\n",
    "\n",
    "# load it with pickle\n",
    "CART_PIPE = load(open(\"../res/pipe_cart.pkl\", \"rb\"))\n",
    "MLP_PIPE = load(open(\"../res/pipe_mlp.pkl\", \"rb\"))\n",
    "KNN_PIPE = load(open(\"../res/pipe_knn.pkl\", \"rb\"))\n",
    "\n",
    "display(CART_PIPE)\n",
    "display(MLP_PIPE)\n",
    "display(KNN_PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test pipelines\n",
    "test_pipe = taa.test_pipeline([CART_PIPE, MLP_PIPE, KNN_PIPE], xtest, ytest)\n",
    "display(test_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paradoxallement, en utilisant les paramètres trouvés par **GridSearchCV()**, en faisant les mêmes préprocessing on obtient des resultats en precision moins bon qu'avec celui de la partie *I)5)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaisons de plusieurs algorithmes d'apprentissages :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "txt = \"|**Key**|**Classifiers**|\\n|--|--|\\n\"\n",
    "for k, v in taa.CLASSIFIERS.items():\n",
    "    txt += f\"|{k}|{v}|\\n\"\n",
    "\n",
    "Markdown(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run1=taa.run_classifiers(taa.CLASSIFIERS, xtrain_trim_ss, ytrain)\n",
    "taa.results_run_clfs(run1, \"run1\", top=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après le 'run1' le mieux serait de partir sur:\n",
    "- un modèle type **MultiLayersPerceptron** \n",
    "- un modèle type **AdaBoost**\n",
    "\n",
    "Il présentent les meilleures compromis en terme de precision et d'accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage supervisé : Données hétérogènes\n",
    "\n",
    "## Chargement des données et préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_het = pd.read_csv(CREDIT_SCORE_HET, sep=\"\\t\", header=None, na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taa.explore_data(df_credit_het, \"def_credit_het\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de donnée 'credit.data' présente 16 colonnes/variables et 688 lignes/enregistrements.\n",
    "\n",
    "Chaque enregistrement est une demande de crédit, pour chaque demandeur est renseigné 13 variables d'entrée et 1 variable de sortie. On distingues deux types de variables:\n",
    "- **Numériques** : continues ou discrètes -> 1, 2, 7, 10, 13, 14 + **15**\n",
    "- **Catégorielles** : -> 0, 3, 4, 5, 6, 8, 9, 11, 12\n",
    "\n",
    "La colonne '**15**' est la variable de sortie que l'on va essayer de prédire à parir des variables d'entrée. \n",
    "Elle a deux modalités:\n",
    "- \"+\" / 1 : (44.33%)\n",
    "- \"-\" / 0 : (55.67%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_prior = taa.calc_prior_accuracy(df_credit_het[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_COLS = [0, 3, 4, 5, 6, 8, 9, 11, 12]\n",
    "NUM_COLS = [1, 2, 7, 10, 13, 14]\n",
    "\n",
    "# to numpy array\n",
    "X, Y = df_credit_het.values[:, :15], df_credit_het.values[:, 15]\n",
    "\n",
    "# separate into X_num, X_cat and Y arrays\n",
    "X_num = X[:, NUM_COLS]\n",
    "X_num = X_num.astype(np.float64)\n",
    "\n",
    "X_cat = X[:, CAT_COLS]\n",
    "\n",
    "Y[Y == \"+\"] = 1\n",
    "Y[Y == \"-\"] = 0\n",
    "Y = Y.astype(np.float64)\n",
    "\n",
    "# without NA\n",
    "without_na = ~np.isnan(X_num).any(axis=1)\n",
    "X_num_nona = X_num[without_na]\n",
    "Y_nona = Y[without_na]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Normalisation des variables continues :\n",
    "\n",
    "Par continues on entend toute valeurs numériques trouvées dans le jeu de donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling X_num\n",
    "stdScale=StandardScaler()\n",
    "X_num_nona_ss = stdScale.fit_transform(X_num_nona)\n",
    "\n",
    "# Min max scaling X_num\n",
    "mmScale= MinMaxScaler()\n",
    "X_num_nona_mm = mmScale.fit_transform(X_num_nona)\n",
    "\n",
    "# run\n",
    "run2_vanilla = taa.run_classifiers(taa.CLASSIFIERS, X_num_nona, Y_nona)\n",
    "run2_ss = taa.run_classifiers(taa.CLASSIFIERS, X_num_nona_ss, Y_nona)\n",
    "run2_mm = taa.run_classifiers(taa.CLASSIFIERS, X_num_nona_mm, Y_nona)\n",
    "\n",
    "taa.results_run_clfs(run2_vanilla, \"run2_vanilla\", scores=[\"test_accuracy\", \"test_roc_auc\"])\n",
    "taa.results_run_clfs(run2_mm, \"run2_mm\", scores=[\"test_accuracy\", \"test_roc_auc\"])\n",
    "taa.results_run_clfs(run2_ss, \"run2_ss\", scores=[\"test_accuracy\", \"test_roc_auc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **ROC AUC** est l'aire sous la courbe (AUC) d'un ROC, une courbe qui rend compte de la sensibilité/recall(en y) et de la 1-spécificité(en x). Plus cette valeur est proche de 1, meilleur est le classifieur.\n",
    "\n",
    "On remarque que les valeurs de ROC fluctuent peu entre run2_vanilla, run2_mm et run2_ss. Idem pour les accuracy. Ce qui change c'est le type de classifieurs qui va se retrouver en tête. On retrouve des RandomForrest, des MultiLayersPerceptron, des AdaBoosts et des Baggings (mais les Baggings ils sont lents à fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement de données manquantes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# for categorical data\n",
    "X_cat_imp = np.copy(X_cat)\n",
    "X_cat_imp[pd.isna(X_cat_imp)] = \"NA\" #cause np.nan is a float \n",
    "for i in range(len(CAT_COLS)):       \n",
    "    unique_val, val_idx = np.unique(X_cat_imp[:, i], return_inverse=True) \n",
    "    X_cat_imp[:, i] = val_idx\n",
    "\n",
    "imp_cat = SimpleImputer(missing_values=\"NA\", strategy='most_frequent')                                                                           \n",
    "X_cat_imp[:, range(5)] = imp_cat.fit_transform(X_cat_imp[:, range(5)])\n",
    "\n",
    "#  for numerical data\n",
    "X_num_imp = np.copy(X_num)\n",
    "imp_num = SimpleImputer(missing_values=np.nan, strategy='mean') \n",
    "X_num_imp = imp_num.fit_transform(X_num_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les variables 'catégorielles', on remplace chaque modalités par un nombre entier, et ce dans chaque colonne. Les valeurs \"NA\" sont remplacé par la modalité la plus présente dans la colonne.\n",
    "\n",
    "Pour les variables 'numériques', on remplace chaque \"NA\" par la moyenne de la colonne.\n",
    "\n",
    "Mais est-ce que cela ne rajoute t'il pas du bruit ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement de variables catégorielles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "X_cat_imp_bin = encoder.fit_transform(X_cat_imp).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, **OneHotEncoder()** va transformer les modalités multiclasse en modalité binaire, elle ajoute des colonnes si nécessaire:\n",
    "- si 1 colonne à 2 modalités -> crée 1 colonne binaire\n",
    "- si 1 colonne à 3 modalités -> crée 2 colonne binaire\n",
    "- si 1 colonne à 4 modalités -> crée 2 colonne binaire\n",
    "- si 1 colonne à 5 modalités -> crée 3 colonne binaire\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling X_num_imp\n",
    "stdScale=StandardScaler()\n",
    "X_num_imp_ss = stdScale.fit_transform(X_num_imp)\n",
    "\n",
    "# Min max scaling X_num_imp\n",
    "mmScale= MinMaxScaler()\n",
    "X_num_imp_mm = mmScale.fit_transform(X_num_imp)\n",
    "\n",
    "# bind X_cat_imp_binary with X_num_imp\n",
    "X_combined = np.concatenate((X_num_imp, X_cat_imp_bin), axis=1)\n",
    "X_combined_mm = np.concatenate((X_num_imp_ss, X_cat_imp_bin), axis=1)\n",
    "X_combined_ss = np.concatenate((X_num_imp_mm, X_cat_imp_bin), axis=1)\n",
    "\n",
    "# run\n",
    "run3_vanilla = taa.run_classifiers(taa.CLASSIFIERS, X_combined, Y)\n",
    "run3_ss = taa.run_classifiers(taa.CLASSIFIERS, X_combined_mm, Y)\n",
    "run3_mm = taa.run_classifiers(taa.CLASSIFIERS, X_combined_ss, Y)\n",
    "\n",
    "taa.results_run_clfs(run3_vanilla, \"run3_imp_vanilla\", scores=[\"test_accuracy\", \"test_roc_auc\"])\n",
    "taa.results_run_clfs(run3_ss, \"run2_imp_ss\", scores=[\"test_accuracy\", \"test_roc_auc\"])\n",
    "taa.results_run_clfs(run3_mm, \"run2_imp_mm\", scores=[\"test_accuracy\", \"test_roc_auc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grand bond en avant en ce qui concerne la ROC AUC et l'accuracy, avec l'ajout des variables catégorielles.\n",
    "Se dispute le podium les RandomForrest et les Baggings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage supervisé sur des données textuelles : Feature engineering et Classification \n",
    "\n",
    "## Lecture et préparation des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = pd.read_csv(SPAM, sep = \"\\t\", header = None)\n",
    "df_spam.rename(columns = {0 : \"Status\", 1 : \"Value\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taa.explore_data(df_spam, \"df_spam\", DPI=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de donnée 'SMSSpamCollection.data' est constitué de 5572 lignes et 2 colonnes/variables.\n",
    "\n",
    "- var 'Values' : unique pour la grande majorité des lignes (5169 valeurs uniques)\n",
    "- var 'Status' : à prédire, deséquilibré avec ~85% sont en \"ham\" et ~15% en \"spam\"\n",
    "\n",
    "Dans le cadre des spams que veut on ? Souhaitons nous tous les bloquer (recall max) ou bien on veut être sûr de ne pas se tromper (precision max)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_prior = taa.calc_prior_accuracy(df_spam[\"Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_spam[\"Status\"].values\n",
    "X = df_spam[\"Value\"].values\n",
    "Y[Y == \"spam\"] = 1\n",
    "Y[Y == \"ham\"] = 0\n",
    "Y = Y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', min_df = 10)\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "X_vec = X_vec.toarray()\n",
    "\n",
    "run4 = taa.run_classifiers(taa.CLASSIFIERS, X_vec, Y)\n",
    "taa.results_run_clfs(run4, \"run4\", scores=[\"test_accuracy\", \"test_roc_auc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf–idf term weighting : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfid = TfidfTransformer(smooth_idf=False)\n",
    "X_vec_tfid = tfid.fit_transform(X_vec)\n",
    "X_vec_tfid = X_vec_tfid.toarray()\n",
    "\n",
    "run4_tfid = taa.run_classifiers(taa.CLASSIFIERS, X_vec_tfid, Y)\n",
    "taa.results_run_clfs(run4_tfid, \"run4_tfid\", scores=[\"test_accuracy\", \"test_roc_auc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TruncatedSVD :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# 100 concepts\n",
    "svd100 = TruncatedSVD(n_components=100, n_iter=20, random_state=1)\n",
    "X_vec_tfid_svd100 = svd100.fit_transform(X_vec_tfid)\n",
    "\n",
    "run4_tfid_svd100 = taa.run_classifiers(taa.CLASSIFIERS, X_vec_tfid_svd100, Y)\n",
    "taa.results_run_clfs(run4_tfid_svd100, \"run4_tfid_svd100\", scores=[\"test_accuracy\", \"test_roc_auc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : 100 components ==> valeur recommandé par sklearn pour faire du 'Latent Semantic Analysis' (LSA)\n",
    "\n",
    "\"overfitting ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "PIPE_TEXT_ADA = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(stop_words='english', min_df = 10)), \n",
    "    (\"tfid\", TfidfTransformer(smooth_idf=False)), \n",
    "    (\"svd\", TruncatedSVD(n_components=100, n_iter=20, random_state=1)),\n",
    "    ('estimator', AdaBoostClassifier(n_estimators=120, random_state=1))\n",
    "])\n",
    "\n",
    "PIPE_TEXT_MLP = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(stop_words='english', min_df = 10)),\n",
    "    (\"tfid\", TfidfTransformer(smooth_idf=False)), \n",
    "    (\"truncatedSVD\", TruncatedSVD(n_components=100, n_iter=20, random_state=1)),\n",
    "    ('estimator', MLPClassifier(hidden_layer_sizes=(100, 50), random_state=1))\n",
    "])\n",
    "\n",
    "display(PIPE_TEXT_ADA)\n",
    "display(PIPE_TEXT_MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application sur un autre jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp = pd.read_csv(YELP, header = 0, sep = ';', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taa.explore_data(df_yelp, \"df_yelp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_prior = taa.calc_prior_accuracy(df_yelp[\"Stars\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_yelp[\"Text\"].values\n",
    "Y = df_yelp[\"Stars\"].values\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.5, random_state=1)\n",
    "\n",
    "PIPE_TEXT_ADA = fit_pipeline(PIPE_TEXT_ADA, xtrain, ytrain)\n",
    "PIPE_TEXT_MLP = fit_pipeline(PIPE_TEXT_MLP, xtrain, ytrain)\n",
    "\n",
    "#they are heavy\n",
    "ypred_ADA = PIPE_TEXT_ADA.predict(xtest)\n",
    "ypred_MLP = PIPE_TEXT_MLP.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taa.test_pipeline([PIPE_TEXT_ADA, PIPE_TEXT_MLP], xtest, ytest, score_params={'average': 'weighted'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au final ça marche pusique que l'on dépasse largement l'accuracy a du random (~0.27). Mais ce n'est pas très haut pour autant. Seulement la moitié des calls sont bons.\n",
    "\n",
    "Ici, notre variable à prédire n'est pas binaire, elle a 5 modalités qui sont **ordinales**. Peut-être qu'un classifieur n'est pas adapté pour ce genre de modalité. Par exemple, si la valeur à prédire de 4 mais que le call soit de 1 ou de 5, l'erreur sera equivalente pour un classifieur.\n",
    "\n",
    "Peut-être une qu'un regresseur serait plus adapté... l'ennui c'est que les modalités sont discrètes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c071d5e2380cba22642a1ed4451cf46f6f551b1bc209e663b38d0c370a67b9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
